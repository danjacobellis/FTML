{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf6cb26c-1693-4d48-9899-bd57cd0a081b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-07 17:40:44.575444: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-07 17:40:45.346261: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-07 17:40:45.346311: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-07 17:40:45.346318: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from common_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e2dcd6af-2965-4464-9d6f-10650aa13e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def codec_gif(rgb):\n",
    "    return tf.io.decode_gif(tfio.image.encode_gif(np.expand_dims(rgb,0)))\n",
    "\n",
    "def codec_jpeg(rgb,quality):\n",
    "    return tf.io.decode_jpeg(tf.io.encode_jpeg(rgb,quality=quality))\n",
    "\n",
    "def ssim_m(img1,img2):\n",
    "    return tf.image.ssim_multiscale(img1,img2,255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d8236ce9-ec24-4a81-8584-955774540f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4e1a8c-a54a-47a2-8233-4d22cd16675b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 629ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "adding +- 1 to image\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "image_filename_list = glob.glob(\"imagenet_crops/*.png\")\n",
    "model = load_model();\n",
    "perturbation_bits = [0,1,2,4]\n",
    "codecs = [lambda img : img,\n",
    "          lambda img : codec_gif(img),\n",
    "          lambda img : codec_jpeg(img,100),\n",
    "          # lambda img : codec_jpeg(img,50),\n",
    "          # lambda img : codec_jpeg(img,20),\n",
    "          # lambda img : codec_jpeg(img,10),\n",
    "          # lambda img : codec_jpeg(img,5),\n",
    "          lambda img : codec_jpeg(img,0)]\n",
    "accuracy = np.zeros((len(image_filename_list),\n",
    "                     len(perturbation_bits),\n",
    "                     len(codecs),\n",
    "                    ))\n",
    "quality = np.zeros((len(image_filename_list),\n",
    "                     len(perturbation_bits),\n",
    "                     len(codecs),\n",
    "                    ))\n",
    "for (i_img,image_filename) in enumerate(image_filename_list):\n",
    "    rgb = png_to_rgb(image_filename)\n",
    "    input_label, gradient = fgsm(model,rgb)\n",
    "    for (i_bit, bit) in enumerate(perturbation_bits):\n",
    "        if (bit == 0):\n",
    "            attacked_img = rgb\n",
    "        else:\n",
    "            attacked_img = sg_attack(rgb,tf.sign(gradient),bit)\n",
    "        for (i_codec,codec) in enumerate(codecs):\n",
    "            test_img = np.squeeze(codec(attacked_img))\n",
    "            test_label, _ = fgsm(model,test_img)\n",
    "            quality[i_img,i_bit,i_codec] = ssim_m(rgb,test_img)\n",
    "    clear_output()\n",
    "        \n",
    "#     rgb = [png_to_rgb(image_filename)]\n",
    "#     rgb.append(codec_gif(rgb[0]))\n",
    "#     for quality in [0,5,10,20,50,100]:\n",
    "#         rgb.append(codec_jpeg(rgb[0],quality))\n",
    "\n",
    "#         \n",
    "\n",
    "#     attacked_label, _ = fgsm(model,attacked_img)\n",
    "#     print(attacked_label)\n",
    "#     print(\"ssim\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1c4203-4f62-42f5-b53c-05ecae3a450a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
