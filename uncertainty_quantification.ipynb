{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "267e4f8c-85dd-4f36-9ee4-0462952afe5d",
   "metadata": {
    "tags": [
     "remove-nb-cell"
    ]
   },
   "source": [
    "# A review of uncertainty quantification in deep learning\n",
    "\n",
    "[Paper](https://www.sciencedirect.com/science/article/pii/S1566253521001081)\n",
    "\n",
    "[Slides](https://danjacobellis.github.io/FTML/uncertainty_quantification.slides.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e072a5-d669-4465-9a53-03cf7f807acd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "<script>\n",
    "    document.querySelector('head').innerHTML += '<style>.slides { zoom: 1.75 !important; }</style>';\n",
    "</script>\n",
    "\n",
    "<center> <h1>\n",
    "Uncertainty quantification in deep learning\n",
    "</h1> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335216c5-d35f-4654-83d9-a9e53d4c8abb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Uncertainty quantification\n",
    "* According to [US Dept of energy (2009)](https://science.osti.gov/-/media/ascr/pdf/program-documents/docs/Nnsa_grand_challenges_report.pdf), uncertainty from many sources should be considered\n",
    "  * Stochastic measurement error\n",
    "  * Limitations of theoretical models\n",
    "  * Numerical representations of models\n",
    "  * Approximations\n",
    "  * Human error\n",
    "  * Ignorance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7877026d-cc07-477e-9a74-145c0fa8bfcb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Predictive uncertainty\n",
    "\n",
    "* Consider a statistical learning model that makes predictions $\\hat{y}$ based on previously seen data $(x_{\\text{train}},y_{\\text{train}})$\n",
    "* The model's predictions will have some error $e = y_{\\text{GT}}-\\hat{y}$\n",
    "* We can never know the actual error $e$\n",
    "* However, we can try to characterize our confidence in $\\hat{y}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfb1e97-a80f-4db5-85b6-65f5274b12e4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Aleatoric Uncertainty\n",
    "\n",
    "* Variation that is consistant across repititions of an experiement\n",
    "* Often possible to characterize the distribution accurately"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d908616a-eca1-426a-aee4-117c3b55ee01",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "<p style=\"text-align:center;\">\n",
    "<img src=\"_images/aleatoric.png\" width=600 height=600 class=\"center\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dbcb24-df91-4b9f-96a9-d5217a5d3a02",
   "metadata": {
    "tags": [
     "remove-nb-cell"
    ]
   },
   "source": [
    "![](img/aleatoric.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70bc89d-b817-41e2-9c8e-4f3055a2eb5f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Epistemic Uncertainty\n",
    "\n",
    "* Lack of knowledge\n",
    "* Imperfect model or model parameters\n",
    "* Difficult to chacterize the distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4297d1b8-4b5b-418e-b1ba-eb508921f46f",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "<p style=\"text-align:center;\">\n",
    "<img src=\"_images/aleatoric_epistemic.jpg\" width=500 height=500 class=\"center\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e30f710-8eaf-4a94-b803-977d0db88558",
   "metadata": {
    "tags": [
     "remove-nb-cell"
    ]
   },
   "source": [
    "![](img/aleatoric_epistemic.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6b95cc-595f-4f77-ae56-9d850d5034cf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Uncertainty propagation in forward problem\n",
    "\n",
    "* Example: Determine uncertainty in restistance from measurements of voltage and current.\n",
    "\n",
    "$$R = h(V,I)= \\frac{V}{I}$$\n",
    "$$f_R(r) = f_{V, I}\\left(h^{-1}(r)\\right) \\left|\\text{det}(\\mathbf J\\{h^{-1} \\}) \\right|$$\n",
    "\n",
    "$$\\sigma_R=R\\sqrt{\\left(\\frac{\\sigma_V}{V}\\right)^2 +\\left(\\frac{\\sigma_I}{I} \\right)^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def071b2-8ab2-44af-a281-7df0255a17d5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Uncertainty in inverse problem\n",
    "\n",
    "* Consider an acoustic propagation model governed by the wave equation $c^2 \\nabla^2 p = \\frac{\\partial^2 p}{\\partial t^2}$\n",
    "  * We can check if the parameters fit the data using the forward model\n",
    "  * Many combinations of parameter values will fit the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2cc057-2f3e-4cee-b617-66097b092e20",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "<p style=\"text-align:center;\">\n",
    "<img src=\"_images/measured_modeled.png\" width=600 height=600 class=\"center\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3d195b-5dfe-414c-a677-727dc0bd2ee5",
   "metadata": {
    "tags": [
     "remove-nb-cell"
    ]
   },
   "source": [
    "![](img/measured_modeled.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65694035-3b78-466f-8a3c-431b9ff601ac",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Sources of uncertainty in deep learning\n",
    "* Aleatoric\n",
    "    * Limited computational resources\n",
    "    * Limited training data\n",
    "* Epistemic\n",
    "    * Data collection process\n",
    "    * Accuracy of training data\n",
    "    * Distribution drift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c64f14b-5816-4fde-adc1-1a46bfe053c9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Bayesian neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6f84a3-41a1-4f9e-a676-5ecdffc06483",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "<p style=\"text-align:center;\">\n",
    "<img src=\"_images/BNN.png\" width=600 height=600 class=\"center\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97155d18-1f1f-4dc5-9c2c-bf805b602337",
   "metadata": {
    "tags": [
     "remove-nb-cell"
    ]
   },
   "source": [
    "![](img/BNN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33297379-f7fc-422b-9c47-8c0769846899",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Bayesian neural networks\n",
    "\n",
    "[BNN](https://arxiv.org/pdf/2007.06823.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68d5f74-5ac4-4c76-ac3c-edc1854d57ad",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "<p style=\"text-align:center;\">\n",
    "<img src=\"_images/bnn_arch.png\" width=600 height=600 class=\"center\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db507c3-ffab-4480-b315-38859c52f70f",
   "metadata": {
    "tags": [
     "remove-nb-cell"
    ]
   },
   "source": [
    "![](img/bnn_arch.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cc11db-db5e-4403-a5c7-03214a895712",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Monte Carlo dropout\n",
    "\n",
    "* Monte carlo sampling can be used to obtain posterior in BNN\n",
    "  * Extremely expensive. Limited to shallow networks.\n",
    "* Dropout is a common regularization technique in NNs\n",
    "  * randomly drop units to prevent excessive codependence\n",
    "  * [Dropout training approximates Bayesian inference](https://arxiv.org/pdf/1506.02142.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc8c83a-43ca-45d5-a05e-70700048ce0e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "<p style=\"text-align:center;\">\n",
    "<img src=\"_images/bayes_seg_net.png\" width=600 height=600 class=\"center\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4883a5-c148-4474-b017-55f6db9703b3",
   "metadata": {
    "tags": [
     "remove-nb-cell"
    ]
   },
   "source": [
    "[bayesian segnet](https://arxiv.org/pdf/1511.02680.pdf)\n",
    "![](img/bayes_seg_net.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17a6622-505d-48f9-809d-21cd4dd7a2de",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Variational inference\n",
    "\n",
    "* Frame the Bayesian inference problem as an optimization problem\n",
    "* Approximate posterior distribution over the weights of the NN\n",
    "* Minimize KL divergence between variational distribution and true posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729baad2-dd6d-4e19-a812-6f9640ca188b",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "<p style=\"text-align:center;\">\n",
    "<img src=\"_images/vi_scal_uncer.png\" width=600 height=600 class=\"center\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b287fd18-b4ea-4e8a-b35c-0f9eabd04067",
   "metadata": {
    "tags": [
     "remove-nb-cell"
    ]
   },
   "source": [
    "[Scalable Uncertainty](https://arxiv.org/pdf/2003.03396.pdf)\n",
    "![](img/vi_scal_uncer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4a4914-1c72-44df-a76a-4b4fc81f5f3f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Variational autoencoders\n",
    "\n",
    "* Maps high-dimensional data to low-dimensional latent variables\n",
    "* Provides a generative model that can be used for UQ\n",
    "\n",
    "[UQ using generative models](https://arxiv.org/pdf/1910.10046.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f577fce-7b21-4d62-82bd-e57ab18a323f",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "<p style=\"text-align:center;\">\n",
    "<img src=\"_images/uq_gen_mnist.png\" width=600 height=600 class=\"center\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955c6345-5c91-4e93-8816-d26c59be2833",
   "metadata": {
    "tags": [
     "remove-nb-cell"
    ]
   },
   "source": [
    "![](img/uq_gen_mnist.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cf95f6-b325-4be6-9af2-a6bf121cbd4e",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "## Bayes by backprop\n",
    "\n",
    "* Minimize variational free energy\n",
    "\n",
    "![](img/bbb.png)\n",
    "\n",
    "[weight uncertainty](https://arxiv.org/pdf/1505.05424.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45915791-955b-4990-b6f7-13d29f3979e2",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "## Laplacian approximations\n",
    "\n",
    "* Build a gaussian distribution around the true posterior\n",
    "  * Use a taylor expansion around the MAP\n",
    "\n",
    "![](img/laplace_sd.png)\n",
    "\n",
    "[laplacian](https://openreview.net/pdf?id=Skdvd2xAZ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfa4e1c-15ad-4375-805c-8d47d3d15c52",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Ensemble techniques\n",
    "\n",
    "* An ensemble of models can enchance predictive performance\n",
    "* How can we use an ensemble to generate uncertainty estimates?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffad3190-32fa-4afe-8f26-685c3c1e844b",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "<p style=\"text-align:center;\">\n",
    "<img src=\"_images/ensemble.png\" width=600 height=600 class=\"center\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984d05c8-5d7c-4c28-af6e-915b7379f0fc",
   "metadata": {
    "tags": [
     "remove-nb-cell"
    ]
   },
   "source": [
    "![](img/ensemble.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe78b884-7941-4ec0-b0b3-5ba3a3df8918",
   "metadata": {
    "tags": [
     "remove-nb-cell"
    ]
   },
   "source": [
    "[brain](https://arxiv.org/pdf/1807.07356.pdf)\n",
    "\n",
    "![](img/ensemble_brain.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a88555-6948-4550-984d-3ce47c3aac4b",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "## Ensemble techniques\n",
    "![](img/michigan.png)\n",
    "\n",
    "[air pollution](https://arxiv.org/pdf/1911.04061.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
