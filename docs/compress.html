
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Lossy compression to prevent evasion and poisoning &#8212; Dan Jacobellis | FTML</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/theme.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="A review of uncertainty quantification in deep learning" href="uncertainty_quantification.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section class="tex2jax_ignore mathjax_ignore" id="lossy-compression-to-prevent-evasion-and-poisoning">
<h1>Lossy compression to prevent evasion and poisoning<a class="headerlink" href="#lossy-compression-to-prevent-evasion-and-poisoning" title="Permalink to this headline">¶</a></h1>
<p><a class="reference external" href="https://danjacobellis.github.io/FTML/compress.slides.html">Slides</a></p>
<section id="evasion">
<h2>Evasion<a class="headerlink" href="#evasion" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Exploit knowledge a model that’s already been trained</p></li>
<li><p>Example: email spam filter</p>
<ul>
<li><p>Attacker wants to avoid detection while preserving the semantic content an email</p></li>
<li><p>Full or partial knowledge of model can be used to find “magic words” that cause an email to be classified as not spam</p></li>
</ul>
</li>
</ul>
</section>
<section id="poisoning">
<h2>Poisoning<a class="headerlink" href="#poisoning" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Attacker contaminates dataset, usually with the goal of introducing a backdoor</p></li>
<li><p>Example: facial recognition</p>
<ul>
<li><p>Attacker wants to prevent facial recognition from working on one or more subjects</p></li>
<li><p>Attacker uploads altered image to public where dataset is sourced for training</p></li>
</ul>
</li>
</ul>
</section>
<section id="fast-gradient-sign-method">
<h2>Fast gradient sign method<a class="headerlink" href="#fast-gradient-sign-method" title="Permalink to this headline">¶</a></h2>
<div class="math notranslate nohighlight">
\[x_{\text{adv}} = x + \epsilon*\text{sign}(\nabla_xJ(\theta, x, y))\]</div>
<p><img alt="" src="_images/doog.png" /></p>
</section>
<section id="robust-features">
<h2>“Robust” features<a class="headerlink" href="#robust-features" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>“Overall, attaining models that are robust and interpretable will require explicitly encoding human priors into the training process”</p></li>
</ul>
<p><img alt="" src="_images/robust_doog.png" /></p>
</section>
<section id="lossy-compression">
<h2>Lossy compression<a class="headerlink" href="#lossy-compression" title="Permalink to this headline">¶</a></h2>
<p><img alt="" src="_images/lossy_lossless.png" /></p>
</section>
<section id="lossy-compression-to-prevent-evasion">
<h2>Lossy compression to prevent evasion<a class="headerlink" href="#lossy-compression-to-prevent-evasion" title="Permalink to this headline">¶</a></h2>
<p><img alt="" src="_images/JPEG_evasion1.png" /></p>
</section>
<section id="id1">
<h2>Lossy compression to prevent evasion<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<p><img alt="" src="_images/JPEG_evasion2.png" /></p>
</section>
<section id="visual-perception-of-quantization">
<h2>Visual perception of quantization<a class="headerlink" href="#visual-perception-of-quantization" title="Permalink to this headline">¶</a></h2>
<p><img alt="" src="_images/dither.png" /></p>
<ul class="simple">
<li><p>Most perturbations are imperceptible if contained in the four least significant bits.</p></li>
</ul>
</section>
<section id="defending-against-larger-perturbations">
<h2>Defending against larger perturbations<a class="headerlink" href="#defending-against-larger-perturbations" title="Permalink to this headline">¶</a></h2>
<p><img alt="" src="_images/jpeg_vs_gif.png" /></p>
</section>
<section id="how-lossy-to-compress">
<h2>How lossy to compress?<a class="headerlink" href="#how-lossy-to-compress" title="Permalink to this headline">¶</a></h2>
<div class="math notranslate nohighlight">
\[\begin{split} \text{Performance on perturbed test sample} = \begin{cases} \text{label confidence} &amp; \text{label is correct} \\ -\text{label confidence} &amp; \text{label is incorrect} \end{cases}\end{split}\]</div>
<p><img alt="" src="_images/accuracy_vs_fidelity.png" /></p>
</section>
<section id="gradient-matching">
<h2>Gradient matching<a class="headerlink" href="#gradient-matching" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Proposed in 2020 as a more efficient method to poison large datasets</p></li>
<li><p>Attacker chooses a specific image and chooses a label that they want the image to be classified as</p></li>
<li><p>Using small perturbations to as little as 0.1% of the dataset, the chosen image can be classified as desired by the attacker</p></li>
<li><p>Requires larger perturbations that evasion attacks but are still mostly imperceptible</p></li>
<li><p>Does not require full knowledge of model architecture. Shown to translate to different models</p></li>
<li><p>Example: Poisoning data by assuming a resnet20 model still works when a VGG13 model is trained</p></li>
</ul>
</section>
<section id="sanitization-to-prevent-poisoning">
<h2>Sanitization to prevent poisoning<a class="headerlink" href="#sanitization-to-prevent-poisoning" title="Permalink to this headline">¶</a></h2>
<p><img alt="" src="_images/CIFAR_compare.png" /></p>
</section>
<section id="compressed-training-to-prevent-poisoning">
<h2>Compressed training to prevent poisoning<a class="headerlink" href="#compressed-training-to-prevent-poisoning" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>An attacker wants the poisoning attack to be imperceptible</p></li>
<li><p>Requires the “poison” part of the data to be mostly contained in the least significant bits or high frequencies</p></li>
<li><p>Instead of training in pixel space, train on quantized transform coefficients</p>
<ul>
<li><p>Discards details in the least significant bits as well as high frequencies</p></li>
<li><p>Details important for classification are kept</p></li>
</ul>
</li>
</ul>
</section>
<section id="audio-classification-baseline">
<h2>Audio classification: baseline<a class="headerlink" href="#audio-classification-baseline" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Dataset: Speech commands</p>
<ul>
<li><p>One second speech segments of 8 possible words</p></li>
<li><p>‘stop,’ ‘down,’ ‘no,’ ‘right,’ ‘go,’ ‘up,’ ‘yes,’ ‘left’</p></li>
</ul>
</li>
<li><p>Baseline model:</p>
<ul>
<li><p>Input size: <span class="math notranslate nohighlight">\(128 \times 128\)</span> time-frequency distribution represented at full precision</p></li>
<li><p>119.52 MiB Feature size</p></li>
<li><p>2.26 GFLOPs per pass</p></li>
<li><p>Achieves test accuracy of about 84%</p></li>
</ul>
</li>
</ul>
</section>
<section id="audio-classification-vq-bnn">
<h2>Audio classification: VQ + BNN<a class="headerlink" href="#audio-classification-vq-bnn" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Encode 2x2 time-frequency blocks via vector quantization</p>
<ul>
<li><p>Use mini-batch k-means to learn codebook of 16 vectors (4 bits)</p></li>
<li><p>Compression ratio of 16:1 (before any entropy coding)</p></li>
</ul>
</li>
<li><p>Input size: <span class="math notranslate nohighlight">\(64 \times 64 \times 4\)</span> binary codes</p></li>
</ul>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p><audio controls="controls"><source src="./_static/left01.wav" type="audio/wav"></audio></p></th>
<th class="head"><p><audio controls="controls"><source src="./_static/right01.wav" type="audio/wav"></audio></p></th>
<th class="head"><p><audio controls="controls"><source src="./_static/yes01.wav" type="audio/wav"></audio></p></th>
<th class="head"><p><audio controls="controls"><source src="./_static/no01.wav" type="audio/wav"></audio></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><audio controls="controls"><source src="./_static/left01_vq.wav" type="audio/wav"></audio></p></td>
<td><p><audio controls="controls"><source src="./_static/right01_vq.wav" type="audio/wav"></audio></p></td>
<td><p><audio controls="controls"><source src="./_static/yes01_vq.wav" type="audio/wav"></audio></p></td>
<td><p><audio controls="controls"><source src="./_static/no01_vq.wav" type="audio/wav"></audio></p></td>
</tr>
</tbody>
</table>
</section>
<section id="id2">
<h2>Audio classification: VQ + BNN<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Input size: <span class="math notranslate nohighlight">\(64 \times 64 \times 4\)</span> binary codes</p></li>
<li><p>3.74 MiB feature size</p></li>
<li><p>Multiply-accumulate instead of FP</p>
<ul>
<li><p>4-way MAC unit uses about 55% of the area of a FP16 FPU</p></li>
<li><p><span class="math notranslate nohighlight">\(4-8 \times\)</span> more power efficient compared to bfloat16</p></li>
<li><p><span class="math notranslate nohighlight">\(&gt;20 \times\)</span> more power efficient compared to FP32</p></li>
</ul>
</li>
<li><p>Achieves test accuracy of about 79% (down from baseline of 84%)</p></li>
</ul>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">FTML</a></h1>








<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="critique_paper2.html">Critique of Paper 2</a></li>
<li class="toctree-l1"><a class="reference internal" href="present_paper10.html">Understanding Black-box Predictions via Influence functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="critique_50y_fairness.html">Critique of “50 Years of Test (Un)fairness”</a></li>
<li class="toctree-l1"><a class="reference internal" href="survey_of_datasets.html">A survey on datasets for fairness-aware machine learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="proposal.html">Proposal: Training on Lossy Encoded Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="failing_loudly.html">Critique of Critique of “Failing Loudly: An Empirical Study of Methods for Detecting Dataset Shift”</a></li>
<li class="toctree-l1"><a class="reference internal" href="uncertainty_quantification.html">A review of uncertainty quantification in deep learning</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Lossy compression to prevent evasion and poisoning</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#evasion">Evasion</a></li>
<li class="toctree-l2"><a class="reference internal" href="#poisoning">Poisoning</a></li>
<li class="toctree-l2"><a class="reference internal" href="#fast-gradient-sign-method">Fast gradient sign method</a></li>
<li class="toctree-l2"><a class="reference internal" href="#robust-features">“Robust” features</a></li>
<li class="toctree-l2"><a class="reference internal" href="#lossy-compression">Lossy compression</a></li>
<li class="toctree-l2"><a class="reference internal" href="#lossy-compression-to-prevent-evasion">Lossy compression to prevent evasion</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id1">Lossy compression to prevent evasion</a></li>
<li class="toctree-l2"><a class="reference internal" href="#visual-perception-of-quantization">Visual perception of quantization</a></li>
<li class="toctree-l2"><a class="reference internal" href="#defending-against-larger-perturbations">Defending against larger perturbations</a></li>
<li class="toctree-l2"><a class="reference internal" href="#how-lossy-to-compress">How lossy to compress?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#gradient-matching">Gradient matching</a></li>
<li class="toctree-l2"><a class="reference internal" href="#sanitization-to-prevent-poisoning">Sanitization to prevent poisoning</a></li>
<li class="toctree-l2"><a class="reference internal" href="#compressed-training-to-prevent-poisoning">Compressed training to prevent poisoning</a></li>
<li class="toctree-l2"><a class="reference internal" href="#audio-classification-baseline">Audio classification: baseline</a></li>
<li class="toctree-l2"><a class="reference internal" href="#audio-classification-vq-bnn">Audio classification: VQ + BNN</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id2">Audio classification: VQ + BNN</a></li>
</ul>
</li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="uncertainty_quantification.html" title="previous chapter">A review of uncertainty quantification in deep learning</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 4.5.0</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="_sources/compress.ipynb.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>