{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "267e4f8c-85dd-4f36-9ee4-0462952afe5d",
   "metadata": {
    "tags": [
     "remove-nb-cell"
    ]
   },
   "source": [
    "# Understanding Black-box Predictions via Influence functions\n",
    "\n",
    "[Paper](http://proceedings.mlr.press/v70/koh17a/koh17a.pdf)\n",
    "\n",
    "[Slides](https://danjacobellis.github.io/FTML/present_paper10.slides.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e072a5-d669-4465-9a53-03cf7f807acd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<script>\n",
    "    document.querySelector('head').innerHTML += '<style>.slides { zoom: 1.75 !important; }</style>';\n",
    "</script>\n",
    "\n",
    "<center> <h1>\n",
    "Understanding Black-box Predictions via Influence functions\n",
    "</h1> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef38317-f6ab-4224-b30e-68f6df04484c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Background and caveats\n",
    "\n",
    "* Our goal is to gain insights about how particular training points influence a model\n",
    "\n",
    "* Loose definition of \"black box\" for this work\n",
    "  * We **do** need to know the relationship between the loss and the model parameters\n",
    "  * However, we don't need to know anything about the model architecture or how it works. Massive DNNs are fine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dacb51d-b1e5-481b-a881-a973e1c88467",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "The idea of examining the influence of particular training samples dates back to at least the 1970s.\n",
    "\n",
    "For example, something that is used commonly in linear regression is Cook's distance.\n",
    "\n",
    "Cook's distance is pretty simple. We want to know how an individual sample affects the prediction\n",
    "\n",
    "To find the influence of the ith point, we train a model without that point, and observe the prediction. Here that would be this y with parentheses i.\n",
    "\n",
    "We sum up the differences between the predictions with that point and without that point and then normalize by the number of parameters p and the mean squared error s squared.\n",
    "\n",
    "That's cook's distance. It's quite useful. We can use it to find influential points for many reasons. We can go see if maybe that point was mislabeled. We can try to understand why that point was influential.\n",
    "\n",
    "We can also use it to try to identify where we should sample the next time we go collect data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e51990-bdc7-4e78-b451-a69302323fcb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Cook's distance\n",
    "\n",
    "* Dennis Cook, 1970: *Detection of influential observation in linear regression*\n",
    "* \"Overall summary statistics (e.g. $R^2$, $\\beta$) ... present a distorted and misleading picture\"\n",
    "* **Cook's distance**: deviation of the model when point $i$ is excluded\n",
    "\n",
    "$$D_i = \\frac {1}{ps^2} \\sum_{j=1}^{n}{(\\hat y _j - \\hat y_{j(i)}})^2$$\n",
    "\n",
    "* Identify influential points\n",
    "* Identify regions to sample when collecting subsequent data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb329b2-1bdd-4afc-973a-eccbcebc184f",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "A related quantity is the leverage. You can think of this as the degree to which the ith measured value influences the ith predicted value.\n",
    "\n",
    "This is often used to detect outliers. A common heuristic is that if the leverage exceeds some multiple of p over n, the ratio of parameters to samples, then a point is an outlier.\n",
    "\n",
    "Next, I'll define some different types of influence functions but just keep in mind that these functions are trying to do something similar to cook's distance or leverage, where we're looking at how particular point influence the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1154deb5-4ee3-4944-9ba5-7ff3e08e46d9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Leverage \n",
    "\n",
    "* Also known as \"Self-influence\"\n",
    "* Degree to which the $i$th measured value influences the $i$th predicted value\n",
    "$$h_{ii} = \\frac {\\partial \\hat y_i}{\\partial y_i}$$\n",
    "* $ 0 \\leq h_{ii} \\leq 1$\n",
    "* Common heuristic: $x_i$ is an outlier if $h_{ii} > \\frac {2p}{n}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37ff850-8470-4f4e-8464-9150e2de1b27",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "Let's start with the first type of influence function. Suppose you train a model. You minimize the empirical risk, resulting in some estimate of the best model parameters theta hat.\n",
    "\n",
    "This theta hat is a function of the data distribution F. If we had a different set of data that we trained on that came from a different distribution, we would have gotten different estimates for our parameters.\n",
    "\n",
    "The influence function is going to examine how a small perturbation in F affects theta hat.\n",
    "\n",
    "Lets define F prime to be some new distribution that is almost the same as the original, except we've added some mass to a location in the sample space z.\n",
    "\n",
    "The first type of influence function which we denote I theta, is like a derivative. It's the difference in model parameters that we get when changing the distribution in the limit that that change is very small.\n",
    "\n",
    "If we're being very rigorous this is not a normal derivative but a functional one. But I think it's helpful to think about it the same way you think of any other derivative, as a rate of change.\n",
    "\n",
    "So that's the first type of influence function, the rate of change of the model parameters when we add mass to some point in the distribution z.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00817656-9335-4240-a5e3-41de6bf4b13f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Influence function\n",
    "\n",
    "* Consider a model parameter $\\theta$ and our estimate of the best value after training $\\hat \\theta $\n",
    "* $\\hat \\theta$ is a function of the data distribution $F$\n",
    "* The influence function describes the effect on $\\hat \\theta$ when we make a small perturbation to the data\n",
    "* In particular, we will add at location $z$ in the distribution $F$ an infinitesimal mass $\\epsilon \\delta_z$, resulting in a new distribution $F^\\prime$\n",
    "\n",
    "$$F^\\prime = F(1-\\epsilon) + \\epsilon \\delta_z$$\n",
    "\n",
    "* The influence function is the derivative${}^\\dagger$ of a model parameter $\\hat \\theta$ with respect to the distribution $F$. \n",
    "\n",
    "$$\\mathcal I_{\\hat \\theta}(z) = \\frac{d \\hat \\theta}{d F}^\\dagger =  \\lim_{\\epsilon \\to 0} \\left[ \\frac{ \\hat \\theta(F^\\prime) - \\hat \\theta (F) }{\\epsilon}\\right]$$\n",
    "\n",
    "$\\dagger$ The derivative here is a functional derivative. In particular it is a Gateaux derivative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef0db5a-3f24-4c74-96ac-92a6689a3ad4",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "The second type of influence function IL is similar, except instead of looking at the model parameters, we're looking at the loss function.\n",
    "\n",
    "So, this is the rate of change in the loss function as we add mass to some location z."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31a570d-15b4-41a7-af5c-b08b91a11c1c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Influence function\n",
    "\n",
    "* We can define a second type of influence function that describes the effect on the loss when we make a small perturbation to the data\n",
    "\n",
    "$$\\mathcal I_{L}(z) = \\frac{d L}{d F} =  \\lim_{\\epsilon \\to 0} \\left[ \\frac{ \\hat L(F^\\prime) - L (F) }{\\epsilon}\\right]$$\n",
    "\n",
    "* A model is trained resulting in parameters $\\hat \\theta$. We test it on a point $z_{test}$. $\\mathcal I_{L}(z,z_{test})$ is the rate at which the loss on $z_{test}$  increases as we make the training point $z$ more prevalent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d969905f-2940-4bc8-bd6e-6d35ffce995e",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "Finally, we have this third type of influence function I pert\n",
    "\n",
    "Instead of just adding a mass to some point in the distribution, we're also going to remove mass from some other point.\n",
    "\n",
    "So this is basically just a difference between to influence functions of the normal type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01686867-b4ea-4843-a466-4c3634c0a55d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Influence Function\n",
    "\n",
    "* We can also define influence functions that describe the effect of 'moving' a training point\n",
    "\n",
    "$$\\mathcal I_{pert} = \\mathcal I(z_2) -  \\mathcal I(z_1)$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2971e5c1-c537-4d43-8954-9a6247944835",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "So how do we actually calculate these influence functions?\n",
    "\n",
    "Well the simplest approach is to just do something like we did for cook's distance and just train the model with all points except one point located at z. That will give us the influence function at z.\n",
    "\n",
    "Clearly, this can get expensive quickly, so we'd like to have a more efficient method.\n",
    "\n",
    "We could have tried to calculate the gradient of the model parameters or the loss function with respect to the data for example.\n",
    "\n",
    "However, the authors go one step further. Why stop at the first derivative when we can use the second derivative? So that's what they do."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbfcfb8-79c8-4104-9a17-a479d5e6d79c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Empirical influence function\n",
    "\n",
    "### Expensive approach: Leave one out\n",
    "* Train the model with all data, including some sample $z$, resulting in $\\hat \\theta$\n",
    "* To estimate $\\mathcal I_{\\hat \\theta}(z)$, train the model without the point $z$, resulting in $\\hat \\theta _ {(z)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b315ae3-a4da-4f94-9673-906319aafc86",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "We train the model with all of the data, resulting in the estimate of the optimal parameter values theta hat.\n",
    "\n",
    "Starting from there, we locally approximate the loss function as a quadratic.\n",
    "\n",
    "When we do that we get this result for the influence function.\n",
    "\n",
    "We have the gradient of the loss function multiplied by the inverse of the hessian.\n",
    "\n",
    "The hessian is just the matrix of second derivatives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e049ae2-0192-4cce-ac77-068afd015208",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Empirical influence function\n",
    "\n",
    "### Cheaper approach: Locally approximate shape of loss function\n",
    "* Start with a model trained on all of the data, including $z,$ resulting in $\\hat \\theta$\n",
    "* Use a quadratic approximation of the loss function to estimate the effect of \"upweighting\" a sample $z$.\n",
    "\n",
    "$$\\mathcal I_{\\hat \\theta}(z) \\approx -H_{\\hat \\theta} ^{-1} \\nabla L$$\n",
    "\n",
    "* $\\nabla L$ is the gradient. $H$ is the *Hessian,* the matrix of all partial second derivatives.\n",
    "\n",
    "* $-H_{\\hat \\theta} ^{-1} \\nabla L$ is the direction you would move in while optimizing a function using Newton's method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ca9def-9b93-4a08-a12d-ec7dede13d1c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Quadratic approximation\n",
    "\n",
    "### Issue #1: Does the Hessian even exist?\n",
    "\n",
    "* We have to pick a nice loss function so that the Hessian is guaranteed to exist.\n",
    "\n",
    "  * Mean absolute error can be replaced with $\\log \\cosh (s)$. \n",
    "  * Hinge with smooth version $t \\log {\\left(1+\\exp{\\left(\\frac{1-s}{t}\\right)}\\right)}.$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ccdfdb-5faa-46a4-9609-0829bca3fbea",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Quadratic approximation\n",
    "\n",
    "### Issue #2: Computing and storing the Hessian\n",
    "\n",
    "* It is ***very*** expensive to compute the Hessian. Even just storing the Hessian for a large neural network might be impossible.\n",
    "\n",
    "* The \"Pearlmutter trick\" allows us to calculate a matrix-vector product with the hessian $\\mathbf {Hv}$ *exactly* with about as much computation as a single gradient evaluation.\n",
    "\n",
    "* There are variations of how to do this. Some are exact some are not with tradeoffs in complexity.\n",
    "\n",
    "* FOSS libraries rolled out in 2018 that allow you plug in your model and efficiently compute the influence using this method.\n",
    "\n",
    "  * Popular one is [Darkon](https://github.com/darkonhub/darkon)\n",
    "  \n",
    "  * [Example notebook]( https://github.com/darkonhub/darkon-examples/blob/master/cifar10-resnet/influence_cifar10_resnet.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d65b6d-34db-438e-8aaf-c6896cd80796",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Experiments and Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32d5008-d0e4-4c20-8ebf-bf7ac7b5f319",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## How well does the quadratic approximation work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5934153-b165-4170-a981-d5291bb8eec0",
   "metadata": {
    "tags": [
     "remove-nb-cell"
    ]
   },
   "source": [
    "![](img/performance_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9851ba34-2984-421b-b128-8fce1c89c7af",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "<p style=\"text-align:center;\">\n",
    "<img src=\"_images/performance_1.png\" width=650 height=650 class=\"center\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7195b5e8-2ea2-487b-b2c2-03b3f66c2a7a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Do differentiable versions of the loss function work? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03db44b1-c72a-4ffa-a9d9-626c44fac0dc",
   "metadata": {
    "tags": [
     "remove-nb-cell"
    ]
   },
   "source": [
    "![](img/hinge_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da52508-673f-46a2-9b78-0dc8d2e47051",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "<p style=\"text-align:center;\">\n",
    "<img src=\"_images/hinge_1.png\" width=750 height=750 class=\"center\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724ca29d-8563-4e2d-ae8a-b3586765d907",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Find helpful and harmful training samples\n",
    "\n",
    "* Other methods exist to find relevant training samples.\n",
    "  * For example, we can look at the nearest neighbor(s)\n",
    "  \n",
    "* The influence function can tell us if a training sample either helps or hurts when evaluating a particular test sample.\n",
    "  * If $\\mathcal I_{L}(z,z_{test})$ is positive, then the training point $z$ is harmful\n",
    "  * If $\\mathcal I_{L}(z,z_{test})$ is negative, then the training point $z$ is helpful"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8d00db-4282-4e67-9e08-87c6df740e7a",
   "metadata": {
    "tags": [
     "remove-nb-cell"
    ]
   },
   "source": [
    "![](img/harmful_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2d45a3-7a54-400d-a424-d7ea4ac89c85",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "<p style=\"text-align:center;\">\n",
    "<img src=\"_images/harmful_1.png\" width=450 height=450 class=\"center\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877dd2bb-4df5-4010-a459-2116d19135f3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Identify overfitting and compare models\n",
    "\n",
    "* Compare $\\mathcal I_{L}(z,z_{test})$ with the euclidian distance\n",
    "\n",
    "* If the model is overfitting, then all of the most influential training points will be neighbors.\n",
    "\n",
    "* If the model generalizes, then the influential points will be spread out, not just overfit to neighboring points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cedfff5-f66b-44c4-bdb2-50534a8cd2f6",
   "metadata": {
    "tags": [
     "remove-nb-cell"
    ]
   },
   "source": [
    "![](img/influence_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6049dff9-8f4a-4c2c-83ac-c33bf0e236f3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "<p style=\"text-align:center;\">\n",
    "<img src=\"_images/influence_1.png\" width=650 height=650 class=\"center\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7f5356-f1b7-48e0-8660-9ee05d548f5d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Debugging mismatch in distributions\n",
    "\n",
    "* Consider a point the sample space $z$ and the surrounding region\n",
    "* The training data may be very dense or very sparse in this region\n",
    "* When deployed, the density may be quite different\n",
    "* $\\mathcal I_{\\hat \\theta, pert}(z)$ tells us exactly how we should update the model to account for this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b55751f-123a-4008-ac5e-dc01c31b4ad0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Debugging mislabeled examples and identifying places to collect new data\n",
    "\n",
    "* Checking the top 5% highest magnitude influence points gives roughly the same performance as checking 60% of the training data exhaustively"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740f2e93-4539-4aba-b2e4-c333b727b292",
   "metadata": {
    "tags": [
     "remove-nb-cell"
    ]
   },
   "source": [
    "![](img/mislabeled_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48027f4e-687d-4d82-8195-73ea98f74416",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "<p style=\"text-align:center;\">\n",
    "<img src=\"_images/mislabeled_1.png\" width=250 height=250 class=\"center\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447fcdc3-f661-4105-912e-030570a47c5c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Constructing and identifying adversarial examples\n",
    "\n",
    "* Find an example that is difficult or ambiguous to start with\n",
    "* At this point, find the gradient of the loss with respect to the data $\\nabla _x L$\n",
    "* Training on the point $x + \\mu \\nabla _x L$ will massively increase the error rate on any data near $x$\n",
    "* The magnitude of $\\mathcal I_{pert}(z)$ tells us how vulnerable a model is to an attack near $z$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d0a57a-674f-4013-b451-84095a5d56e9",
   "metadata": {
    "tags": [
     "remove-nb-cell"
    ]
   },
   "source": [
    "![](img/adversarial_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4198dc-3f88-47a6-9477-6e3c2aaf2f41",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "<p style=\"text-align:center;\">\n",
    "<img src=\"_images/adversarial_1.png\" width=750 height=750 class=\"center\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aff5122-7f05-4359-be21-73d8493f6ecb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "## Thank you!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
