{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2be97a0b-8b28-4498-9eba-42efb34b5a10",
   "metadata": {},
   "source": [
    "## Proposal: Training on Lossy Encoded Data\n",
    "\n",
    "## Problem/Motivation\n",
    "\n",
    "When learning audio, image, and video models, data are typically stored using conventional lossy codecs such as MPEG, JPEG, and HEVC which perform quantization in the time-frequency or space-frequency transform domains.\n",
    "\n",
    "At training time, data are decoded so that the input layers of a model can expect to receive audio samples or RGB pixel values. This pipeline is counterproductive because the increase in information density that was achieved by the lossy compression must be repeated by the initial layers of the network for most tasks.\n",
    "\n",
    "To large companies such as Amazon, Facebook, this is a small additional cost to training their  end-to-end models with billions of parameters.\n",
    "\n",
    "It has been shown in [Faster Neural Networks Straight from JPEG] that training directly on the quantized transform representation used in JPEG results in faster training and more accurate results. Since standard lossy encoders can have extremely high compression ratios (commonly 200:1 for video) any layers in a network primarily function to increase information density may be eliminated. We speculate that there are a number of other advantages of compressed training with regard to fairness and explainability.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
